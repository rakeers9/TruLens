{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498ed683",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '‚úÖ' (U+2705) (216436497.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    - ‚úÖ LangChain RAG with In-Memory Vector Database\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '‚úÖ' (U+2705)\n"
     ]
    }
   ],
   "source": [
    "# üöÄ **Complete TruLens + LangChain Demo with Interactive Dashboard**\n",
    "\n",
    "## Features Demonstrated:\n",
    "- ‚úÖ LangChain RAG with In-Memory Vector Database\n",
    "- ‚úÖ TruLens Integration and Instrumentation\n",
    "- ‚úÖ Agentic LLM Evaluation\n",
    "- ‚úÖ Interactive Dashboard\n",
    "- ‚úÖ Local Server Deployment\n",
    "- ‚úÖ Advanced Feedback Functions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03084064",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'trulens.apps.langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Feedback, Select, TruSession\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproviders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI \u001b[38;5;28;01mas\u001b[39;00m TruOpenAI\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapps\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TruChain\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdashboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_dashboard\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ All imports successful!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'trulens.apps.langchain'"
     ]
    }
   ],
   "source": [
    "# üì¶ INSTALLATION & IMPORTS\n",
    "# Run this first if packages aren't installed:\n",
    "# !pip install trulens-eval langchain langchain-openai langchain-chroma chromadb tiktoken\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# TruLens imports\n",
    "from trulens.core import Feedback, Select, TruSession\n",
    "from trulens.providers.openai import OpenAI as TruOpenAI\n",
    "from trulens.apps.langchain import TruChain\n",
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f899f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶ë Initialized with db url sqlite:///default.sqlite .\n",
      "üõë Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n",
      "ü¶ë TruLens Session initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Database reset for clean demo\n",
      "‚úÖ Environment setup complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# üîë SETUP ENVIRONMENT\n",
    "\n",
    "# Set OpenAI API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize TruSession\n",
    "tru = TruSession()\n",
    "print(\"ü¶ë TruLens Session initialized\")\n",
    "\n",
    "# Reset database for clean demo (optional)\n",
    "tru.reset_database()\n",
    "print(\"üîÑ Database reset for clean demo\")\n",
    "\n",
    "# Initialize OpenAI models\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c59fbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Created 10 document chunks\n",
      "üîç Vector store created with 10 embeddings\n",
      "‚úÖ Knowledge base setup complete!\n"
     ]
    }
   ],
   "source": [
    "# üìö CREATE ENHANCED KNOWLEDGE BASE\n",
    "\n",
    "# Expanded knowledge base for better RAG demonstration\n",
    "documents_text = [\n",
    "    \"Machine learning is a subset of artificial intelligence (AI) that enables computers to learn and improve from experience without being explicitly programmed. It involves algorithms that can identify patterns in data and make predictions or decisions based on those patterns.\",\n",
    "    \n",
    "    \"Deep learning is a specialized subset of machine learning that uses artificial neural networks with multiple layers (hence 'deep') to model and understand complex patterns in data. It's particularly effective for tasks like image recognition, natural language processing, and speech recognition.\",\n",
    "    \n",
    "    \"Natural Language Processing (NLP) is a branch of artificial intelligence that helps computers understand, interpret, and manipulate human language. NLP combines computational linguistics with statistical, machine learning, and deep learning models to enable computers to process human language in a valuable way.\",\n",
    "    \n",
    "    \"Computer vision is a field of artificial intelligence that enables machines to interpret and make decisions based on visual information from the world. It involves techniques for acquiring, processing, analyzing, and understanding digital images or videos to extract meaningful information.\",\n",
    "    \n",
    "    \"Reinforcement learning is a type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize cumulative reward. The agent learns through trial and error, receiving feedback in the form of rewards or penalties for its actions.\",\n",
    "    \n",
    "    \"Artificial Intelligence (AI) is a broad field of computer science focused on creating machines capable of performing tasks that typically require human intelligence. This includes learning, reasoning, problem-solving, perception, and language understanding.\",\n",
    "    \n",
    "    \"Large Language Models (LLMs) are AI models trained on vast amounts of text data to understand and generate human-like text. Examples include GPT, BERT, and Claude. They can perform various tasks like text completion, translation, summarization, and question answering.\",\n",
    "    \n",
    "    \"Vector databases are specialized databases designed to store and query high-dimensional vectors efficiently. They're crucial for AI applications involving embeddings, similarity search, and retrieval-augmented generation (RAG) systems.\",\n",
    "    \n",
    "    \"Retrieval-Augmented Generation (RAG) is an AI technique that combines information retrieval with text generation. It retrieves relevant information from a knowledge base and uses it to generate more accurate and contextually relevant responses.\",\n",
    "    \n",
    "    \"AI agents are autonomous systems that can perceive their environment, make decisions, and take actions to achieve specific goals. They can be simple rule-based systems or complex learning agents that adapt their behavior based on experience.\"\n",
    "]\n",
    "\n",
    "# Create LangChain documents\n",
    "documents = [\n",
    "    Document(page_content=text, metadata={\"source\": f\"doc_{i}\", \"topic\": text.split()[0].lower()})\n",
    "    for i, text in enumerate(documents_text)\n",
    "]\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"üìÑ Created {len(splits)} document chunks\")\n",
    "\n",
    "# Create in-memory vector store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"ai_knowledge_base\"\n",
    ")\n",
    "\n",
    "print(f\"üîç Vector store created with {vectorstore._collection.count()} embeddings\")\n",
    "print(\"‚úÖ Knowledge base setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3ff820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó RAG Chain created successfully!\n",
      "\n",
      "üß™ Test Query: What is the difference between machine learning and deep learning?\n",
      "üìù Answer: Machine learning is a subset of artificial intelligence that involves algorithms that can identify patterns in data and make predictions or decisions based on those patterns. Deep learning, on the oth...\n",
      "üìö Sources: 3 documents retrieved\n",
      "‚úÖ RAG system working correctly!\n"
     ]
    }
   ],
   "source": [
    "# ü§ñ CREATE LANGCHAIN RAG SYSTEM\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # Retrieve top 3 most relevant chunks\n",
    ")\n",
    "\n",
    "# Create RAG chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": None  # Will use default prompt\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"üîó RAG Chain created successfully!\")\n",
    "\n",
    "# Test the RAG system\n",
    "test_query = \"What is the difference between machine learning and deep learning?\"\n",
    "test_result = rag_chain.invoke({\"query\": test_query})\n",
    "\n",
    "print(f\"\\nüß™ Test Query: {test_query}\")\n",
    "print(f\"üìù Answer: {test_result['result'][:200]}...\")\n",
    "print(f\"üìö Sources: {len(test_result['source_documents'])} documents retrieved\")\n",
    "print(\"‚úÖ RAG system working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15106d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
